{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building an Operational Data Store with Firestore and GCS\n",
                "\n",
                "This notebook implements a multi-layer ODS approach using Google Cloud services. \n",
                "\n",
                "**Architecture (Best Practices):**\n",
                "1. **Operational Layer (Firestore):** Stores recent orders and serves individual document lookups.\n",
                "2. **Aggregate Document Pattern (Firestore):** Instead of real-time aggregation (which can be expensive), we maintain a 'summary' document that stores pre-computed metrics like revenue per category. This is a common and efficient pattern in Firestore.\n",
                "3. **Archive Layer (GCS):** Stores monthly exports for long-term durability and compliance."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 0: Setup\n",
                "\n",
                "Install necessary packages if not already present:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install google-cloud-firestore google-cloud-storage python-dotenv pandas numpy --quiet"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "from datetime import datetime, timedelta\n",
                "from pathlib import Path\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from google.cloud import firestore, storage\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "print(\"Imports OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Credentials\n",
                "\n",
                "Load credentials from the `.env` file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(Path(\"../.env\"))\n",
                "\n",
                "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
                "GCS_BUCKET_NAME = os.getenv(\"GCS_BUCKET_NAME\")\n",
                "\n",
                "print(f\"Project ID: {GCP_PROJECT_ID}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Connect to Firestore"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Connect to Firestore\n",
                "db = firestore.Client(project=GCP_PROJECT_ID)\n",
                "print(\"Connected to Firestore.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Load Data into Firestore\n",
                "\n",
                "Generate 100 synthetic orders and insert into Firestore."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "\n",
                "CATEGORIES = [\"footwear\", \"apparel\", \"accessories\", \"electronics\"]\n",
                "products_data = []\n",
                "for i in range(1, 21):\n",
                "    category = np.random.choice(CATEGORIES)\n",
                "    products_data.append({\n",
                "        \"product_id\": f\"PROD_{i:03d}\",\n",
                "        \"name\": f\"{category.title()} Item {i}\",\n",
                "        \"category\": category,\n",
                "        \"price\": round(np.random.uniform(20, 300), 2),\n",
                "    })\n",
                "\n",
                "REGIONS = [\"North\", \"South\", \"East\", \"West\"]\n",
                "STATUSES = [\"pending\", \"shipped\", \"delivered\", \"returned\"]\n",
                "orders_data = []\n",
                "start_date = datetime.now() - timedelta(days=35)\n",
                "\n",
                "for i in range(1, 101):\n",
                "    product = np.random.choice(products_data)\n",
                "    quantity = np.random.randint(1, 4)\n",
                "    order_date = start_date + timedelta(days=int(np.random.randint(0, 35)),\n",
                "                                        hours=int(np.random.randint(0, 24)))\n",
                "    orders_data.append({\n",
                "        \"order_id\": f\"ORD_{i:05d}\",\n",
                "        \"customer_id\": f\"CUST_{np.random.randint(1, 101):04d}\",\n",
                "        \"region\": np.random.choice(REGIONS),\n",
                "        \"product_id\": product[\"product_id\"],\n",
                "        \"category\": product[\"category\"],\n",
                "        \"unit_price\": product[\"price\"],\n",
                "        \"quantity\": quantity,\n",
                "        \"total\": round(product[\"price\"] * quantity, 2),\n",
                "        \"status\": np.random.choice(STATUSES, p=[0.05, 0.15, 0.75, 0.05]),\n",
                "        \"created_at\": order_date,\n",
                "    })\n",
                "\n",
                "# Batch Insert\n",
                "batch = db.batch()\n",
                "orders_ref = db.collection(\"orders\")\n",
                "for order in orders_data:\n",
                "    doc_ref = orders_ref.document(order[\"order_id\"])\n",
                "    batch.set(doc_ref, order)\n",
                "batch.commit()\n",
                "print(f\"Inserted {len(orders_data)} orders into Firestore.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: The 'Aggregate Document' Pattern\n",
                "\n",
                "Instead of running a heavy query across thousands of orders every time you load a dashboard, we maintain a summary document."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_aggregate_document():\n",
                "    \"\"\"\n",
                "    In a real system, this would be updated on every new order (e.g. via Cloud Functions) \n",
                "    or scheduled every few minutes.\n",
                "    \"\"\"\n",
                "    cutoff = datetime.now() - timedelta(days=30)\n",
                "    docs = db.collection(\"orders\").where(\"created_at\", \">=\", cutoff).where(\"status\", \"!=\", \"returned\").stream()\n",
                "    \n",
                "    summary = {}\n",
                "    for doc in docs:\n",
                "        d = doc.to_dict()\n",
                "        cat = d[\"category\"]\n",
                "        if cat not in summary:\n",
                "            summary[cat] = {\"revenue\": 0, \"orders\": 0}\n",
                "        summary[cat][\"revenue\"] += d[\"total\"]\n",
                "        summary[cat][\"orders\"] += 1\n",
                "        \n",
                "    # Save the summary to a single, dedicated document\n",
                "    db.collection(\"aggregates\").document(\"category_revenue\").set({\n",
                "        \"last_updated\": firestore.SERVER_TIMESTAMP,\n",
                "        \"data\": summary\n",
                "    })\n",
                "    print(\"Aggregate document updated.\")\n",
                "\n",
                "update_aggregate_document()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: Efficient Dashboard Querying\n",
                "\n",
                "Now we get the dashboard metrics by reading just ONE document, rather than hundreds of orders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_dashboard_metrics():\n",
                "    doc = db.collection(\"aggregates\").document(\"category_revenue\").get()\n",
                "    if not doc.exists:\n",
                "        print(\"Aggregate not found. This shouldn't happen if the worker is running.\")\n",
                "        return []\n",
                "    \n",
                "    data = doc.to_dict()[\"data\"]\n",
                "    formatted = []\n",
                "    for c, m in data.items():\n",
                "        formatted.append({\"_id\": c, \"revenue\": round(m[\"revenue\"], 2), \"orders\": m[\"orders\"]})\n",
                "    \n",
                "    return sorted(formatted, key=lambda x: x[\"revenue\"], reverse=True)\n",
                "\n",
                "print(\"Dashboard Results (from Aggregate Document):\")\n",
                "for row in get_dashboard_metrics():\n",
                "    print(f\"  {row['_id']:<15}  ${row['revenue']:>8,.2f}   ({row['orders']} orders)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 6: Archive to GCS\n",
                "\n",
                "Export month-to-date orders to JSONL and upload."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if GCS_BUCKET_NAME and GCS_BUCKET_NAME != \"YOUR_BUCKET_NAME\":\n",
                "    bucket = storage.Client(project=GCP_PROJECT_ID).bucket(GCS_BUCKET_NAME)\n",
                "    export_path = Path(\"./orders_archive.jsonl\")\n",
                "    \n",
                "    month_start = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
                "    docs = db.collection(\"orders\").where(\"created_at\", \">=\", month_start).stream()\n",
                "    \n",
                "    with open(export_path, \"w\") as f:\n",
                "        for doc in docs:\n",
                "            order = doc.to_dict()\n",
                "            order[\"created_at\"] = order[\"created_at\"].isoformat() \n",
                "            f.write(json.dumps(order) + \"\\n\")\n",
                "            \n",
                "    gcs_path = f\"shopstream/orders/{datetime.now().strftime('%Y/%m/%d')}/orders_archive.jsonl\"\n",
                "    bucket.blob(gcs_path).upload_from_filename(str(export_path))\n",
                "    print(f\"Archived to: gs://{GCS_BUCKET_NAME}/{gcs_path}\")\n",
                "else:\n",
                "    print(\"GCS_BUCKET_NAME not set. Archiving skipped.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}